<!DOCTYPE html>
<html>

    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3mobile.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
        <script type="text/javascript">
            function process_submit() {
                document.getElementById("image_preview").style.visibility = "hidden";
                document.getElementById("sign_text").style.visibility = "hidden";
                document.getElementById("audio_player").style.visibility = "hidden";
                
                var input = document.getElementById("sign_image").files[0];
                
                if (input) {
                    var reader = new FileReader();
                    
                    reader.onload = function (e) {
                        var image_data = e.target.result;
                        var image_data_content = image_data.substring(image_data.indexOf(",") + 1);
                        
                        document.getElementById("image_preview").src = image_data;
                        document.getElementById("image_preview").style.visibility = "visible";
                        
                        $.ajax({
                            url: "https://vision.googleapis.com/v1/images:annotate?key=AIzaSyB-zSgtDZm1cgjJDwI0bKUoxHoR0KjO-pU",
                            type: "POST",
                            data: JSON.stringify({
                                "requests": [
                                    {
                                        "image":{
                                            "content": image_data_content
                                        },
                                        "features": [
                                            {
                                                "type": "TEXT_DETECTION",
                                                "maxResults": 10
                                            }
                                        ]
                                    }
                                ]
                            }),
                            contentType: 'application/json',
                            success: function (result) {
                                process_vision_response(result);
                            },
                            error: function (request, status, error) {
                                console.log("ERROR: Request: " + JSON.stringify(request) + ", status: " + status);
                                document.getElementById("sign_text").innerHTML = "ERROR in vision response";
                                document.getElementById("sign_text").style.visibility = "visible";
                            }
                        });
                    };
                    
                    reader.readAsDataURL(input);
                }
                return false;
            }
            
            function process_vision_response(result) {
                console.log("vision response: " + result);
                if (result.responses.length > 0) {
                    var sign_text = result.responses[0].fullTextAnnotation.text;
                    
                    document.getElementById("sign_text").innerHTML = "Sign: " + sign_text;
                    document.getElementById("sign_text").style.visibility = "visible";
                    
                    var dialect = document.querySelector('input[name = "dialect"]:checked').value;
                    console.log("dialect: " + dialect);
                    var gender = document.querySelector('input[name = "gender"]:checked').value;
                    console.log("gender: " + gender);
                    $.ajax({
                        url: "https://texttospeech.googleapis.com//v1beta1/text:synthesize?key=AIzaSyCsrfikbupfgSVSagYg_SqTszfGB2CMF2s",
                        type: "POST",
                        data: JSON.stringify({
                            "input": {
                                "text": sign_text
                            }, 
                            "voice": {
                                "languageCode": dialect, 
                                "ssmlGender": gender
                            }, 
                            "audioConfig": {
                                "audioEncoding":"MP3"
                            }
                        }),
                        contentType: 'application/json',
                        success: function (result) {
                            process_speech_response(result);
                        },
                        error: function (request, status, error) {
                            console.log("ERROR: Request: " + JSON.stringify(request) + ", status: " + status);
                            document.getElementById("sign_text").innerHTML = "ERROR in speech response";
                            document.getElementById("sign_text").style.visibility = "visible";
                        }
                    });
                } else {
                    document.getElementById("sign_text").innerHTML = "ERROR no text in response";
                    document.getElementById("sign_text").style.visibility = "visible";
                }
            }
            
            function process_speech_response(result) {
                console.log("speech response: " + result);

                document.getElementById("audio_player").style.visibility = "visible";
                var audioControl = document.getElementById('audio_player');
                audioControl.onerror = function() {
                    console.log(audioControl.error);
                };
                audioControl.src = "data:audio/mp3;base64," + result['audioContent'];
                audioControl.play();
            }
        </script>
    </head>

    <body>
        <form>
            <fieldset>
                <legend>Take a picture of the sign</legend>
                <input type="file" id="sign_image" accept="image/*" capture="environment">
            </fieldset><br>
            <fieldset>
                <legend>Pick dialect:</legend>
                <input type="radio" name="dialect" id="dialectUS" value="en-US" checked><label>US</label>
                <input type="radio" name="dialect" id="dialectGB" value="en-GB"><label>UK</label>
                <input type="radio" name="dialect" id="dialectIN" value="en-IN"><label>India</label>
                <input type="radio" name="dialect" id="dialectAU" value="en-AU"><label>Australia</label>
                <input type="radio" name="dialect" id="dialectNG" value="en-NG"><label>Nigeria</label>
            </fieldset><br>
            <fieldset>
                <legend>Pick gender:</legend>
                <input type="radio" name="gender" id="genderF" value="FEMALE" checked><label>Female</label>
                <input type="radio" name="gender" id="genderM" value="MALE"><label>Male</label>
                <input type="radio" name="gender" id="genderN" value="NEUTRAL"><label>Neutral</label>
            </fieldset><br>
            <p>
                <input type="submit" value="Submit" onclick="return process_submit()"><br>
            </p>
        </form>
        <p>
            <img src="" height="200" id="image_preview" alt="Image preview..." style="visibility: hidden;"><br>
            <div id="sign_text" style="visibility: hidden;"></div><br>
            <audio controls="true" id="audio_player" src="" style="visibility: hidden;"></audio><br>
        </p>
    </body>

</html>

